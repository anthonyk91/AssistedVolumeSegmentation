# base folder of project.  other path/file names are relative to this path
project_folder: /home/anthony/workspace/annotation/highres_project

# this is a list of paths under the project directory which will hold processing data
# for various data sources.  an example is if there are multiple samples (ie multiple
# specimens that have been recorded), and they each are part of a common distribution,
# the various samples can be recorded here as different subdirectories.  A common distribution
# means that a common segmentation model can be applied to each of the samples.  The
# values under "subdir_paths" are simply labels used for holding processing, and each
# entry corresponds with a source path under source_data_paths, in order.
subdir_paths:
 - sample_121431

# this is a list of source data paths corresponding with various samples in the project.
# each source data path should contain input data, such as a stack of tiff files.
source_data_paths: 
 - /run/media/anthony/a77cfb18-3e3d-4ccd-9f0a-a84acfdf5459/diamond/121431

# specify the format that the source data is stored as.  this needs to be set for each
# source subdirectory. options:
# - "tiff-stack": the path in source_data_paths contains a number of .tiff files (with
#                 file extension .tiff), which are read in order to represent a 3D stack
# - "hdf5": the path in source_data_paths is a file in HDF5 format, which contains a
#                 hdf5 dataset with the name given by source_hdf5_dataset_name. this contains
#                 an array with shape (x, y, z) representing the source data
source_data_format:
 - "tiff-stack"

# name of dataset entry in HDF5 file if HDF5 source data is used.
source_hdf5_dataset_name: "data"

# data_stats is used for holding values used for normalising data.  this is a list
# of values representing mean, std, min, max. this can be calculated with find_stats.py.
# (find_stats can only be run after the overview has been created however, to define the region
# of interest). these values are used to normalise the data values before feeding into the neural
# network training, for example by applying training_data = (source_data - mean) / std.  the
# parameter normalise_method is used to specify the normalising function (currently just "mean_std").
data_stats: [30557.405897, 3475.292571, 5037, 47042]
normalise_method: mean_std

# size of annotation tiles in source pixels.  this is the size of each tile that will be used
# for performing annotation (and each tile that is used for training and inference).  when a
# tile is annotated the full tile must be annotated, eg cell in the tile must be marked as
# each unmarked region is considered background.  in cases where a lot of manual annotation is
# needed then a smaller annotation size may be necessary for practical reasons.  section_dimensions
# and section_input_dimensions need to be <= annotation_size.
annotation_size: [160, 160, 160]

# dimensions of sections extracted from annotated data, for training.  section_input_dimensions
# represents the size of the data section that is used as input for the neural network model.
# section_dimensions should be >= than section_input_dimensions and <= annotation_size for
# each dimension, and represents the size of a piece of data that is used for performing
# data augmentation before cropping the section passed into the network.  as an example this
# section may be warped, scaled, stretched or distorted in various ways before the input
# section is cropped from it.  if section_input_dimensions or annotation_size need to be
# reduced, then section_dimensions should be proportionally larger than section_input_dimensions
section_input_dimensions: [64, 64, 64]
section_dimensions: [80, 80, 80]

# path to installed 3D Slicer executable
slicer_path: /usr/local/bin/Slicer

# define the segmentation method.  there are two options available here,
# - "semantic" specifies that semantic segmentation annotations will be used, where one segment will be used to define
# all of the regions of a class (such as all of the regions inside cells), and different segments
# can represent different classes (such as cell bodies or other kinds of features).  when doing annotation for
# semantic segmentation, in the annotation tool (Slicer) all cell bodies will have the same colour.  Semantic
# segmentation can also be used on data that has been annotated with multiple instances of the same class (ie the
# annotation is instance segmentation), by choosing "semantic" here and setting semantic_segmentation_classes to 1,
# which will treat all of the instance segments as the one class.
# - "instance" specifies that instance segmentation will be used, where all segments are part of the same
# class (such as cells), and various segments represent various instances (eg individual cells).  in the
# annotation tool individual cells will have different colours.
segmentation_method: "semantic"

# If using semantic segmentation, the number of foreground classes needs to be specified. for
# example if only one class is used, to represent cell-bodies, the value would be 1.  If two
# classes are used, for example using a second class to represent a cell feature, then the value
# is 2.  This field is not used for instance segmentation.
semantic_segmentation_classes: 1

# The following parameter is used to specify tiles that are interesting regions and should be
# chosen for generation or annotation (if the command line option is specified.  As an example
# if there are regions in the data that have been recognised as having notable features that
# should be annotated (or generated for verifying), they can be specified here.  The format is
# subdir_number tile_x tile_y tile_z for each tile, for example:
# tiles_of_interest:
#  - 0 35 7 12
#  - 1 12 1 29
tiles_of_interest:

# the following values generally represent paths where output will be stored, and may not
# need to be modified.

# file containing generated reduced view of source data
overview_reduced_data: overviews/sample_stack.nii.gz

# file containing manually annotated overview of source data (in overview_reduced_data)
#overview_coverage: overviews/sample_stack_labelmap.nrrd
overview_coverage: overviews/sample_stack.seg.nrrd

# file containing generated map of annotation pieces
pieces_overview: overviews/annotation_pieces.nrrd

# path containing completed annotated pieces
completed_piece_path: annotated

# path containing completed annotated pieces
inprogress_piece_path: inprogress

# path containing excluded pieces
excluded_piece_path: excluded

# path containing removed files, for example 
removed_piece_path: removed_files

# path containing completed annotated pieces
overviews_path: overviews

# file containing generated data properties
project_data_file: assocs.json

# path to source data
source_piece_path: sources

# training options
# generator_output_path is where generated pieces from the segmentation model will be
# found.  at the moment this should correspond with the experiment output directory
generator_output_path: exp_output

# distribution of pieces to use for training and validation
train_validation_splits: [0.9, 0.1]

# random number seed used for generating training and validation splits, in order to allow
# reproducibility
split_random_seed: 41235

# when generating segmentations after training, specify number of tiles to generate at a time.
# these can then be corrected before performing another training cycle. this value also sets
# the number of tiles that will be processed together when generating a full segmentation of the
# data.  setting a high value can result in a lot of memory being needed (this is influenced by
# num_ensemble_models).
generate_number_tiles: 4

# this specifies the number of different versions of the trained model to save and use for generating
# output annotations.  models saved from different stages of training, and combining the models can
# allow improved accuracy.  a larger number of models will require more memory when processing (along
# with generate_number_tiles).
num_ensemble_models: 2

# set threshold for setting generated segmentations as filled or not.  the values produced
# by the model will be real-valued (floats), and this threshold is used to change them
# to true/false values in the segmentation.
generated_threshold: 0.2

# filename of data generated over a full sample.
full_generated_data_file: generated_data.h5

# method for generating full sample output.
# - real_valued: produce an output array with real-values representing confidence that each
#                position is foreground, which allows a threshold to be chosen afterwards.
#                this is only relevant for semantic segmentation.  in this case the output array
#                generated will be shape (semantic_segmentation_classes, x, y, z), with dtype=float
# - flattened:   produce an output array with integer values representing either semantic segmentation
#                classes or instance segmentations.  the threshold used for setting foreground values
#                is set in generated_threshold.
full_generate_format: "real_valued"
